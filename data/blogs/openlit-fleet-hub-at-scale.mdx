---
title: Fleet Hub Playbook for Multi-Region AI Observability
date: '2025-11-07'
tags: ['openlit', 'opentelemetry', 'llm', 'production', 'fleet-hub']
draft: false
summary: Coordinate fleets of OpenTelemetry collectors for GenAI workloads with OpenLIT Fleet Hub and automatic instrumentation.
authors: ['Aman']
images: ['/static/images/fleet-hub-topology.webp']
---

## Introduction

Multi-model AI platforms rarely run in one place. You juggle GPU schedulers for inference, CPU-heavy retrieval augmentation pipelines, and dozens of fine-tuned assistants built by different pods. Each domain team deploys its own OpenTelemetry Collector with custom processors, and the slightest mistake leaves blind spots that derail incident response. Fleet Hub, OpenLIT’s new control plane, gives you a single view of every collector, policy, and pipeline your AI estate depends on. Combined with the one-line `openlit.init()` instrumentation across Python and TypeScript services, it changes the day-to-day rhythm of operating generative AI systems.

This playbook details how Fleet Hub works, what changes for platform reliability engineers, and the exact steps to integrate it alongside the OpenLIT Operator. You will walk through the configuration needed to register collector fleets, the automation that binds large language model (LLM) services to those fleets, and the governance hooks that keep cost and compliance under control.

## Why It’s Important

Operating production LLM platforms is no longer about a single inference API. Observability leads have to reconcile:

- Regionalized collectors for latency-sensitive GPU clusters, each tuned differently.
- RAG pipelines that fan out across vector databases, embedding providers, and orchestrators like LangChain or LlamaIndex.
- Vendor diversity: OpenAI, Anthropic, Azure OpenAI, Groq, Vertex AI, Mistral and in-house LLMs deployed on Kubernetes.
- Compliance guardrails that demand deterministic routing of telemetry events and retention policies.

Without Fleet Hub, coordination becomes a spreadsheet exercise. You rely on manual GitOps diffs and Slack pings to confirm a collector was patched or scaled. Fleet Hub turns that chaos into a map. It inventories every collector, tags their purpose, and lets you push topology-aware policies (such as scaling, drop rules, tail sampling, or export bindings) across the fleet with a few clicks or API calls. When coupled with OpenLIT’s automatic instrumentation, you gain a contract: engineers stick to `openlit.init()`, and the platform team guarantees consistent traces, metrics, and logs, no matter how many collectors sit between workloads and downstream sinks.

## How to Implement/Do It

### 1. Prerequisites: Automatic Instrumentation Everywhere

Fleet Hub assumes workloads emit OpenTelemetry signals automatically. OpenLIT’s SDKs honor the configuration defined in [`sdk/configuration`](https://docs.openlit.io/latest/sdk/configuration), and the heavy lifting stays inside the agent. Your only code change is initializing once at service startup.

```python
import os
from openlit import init as openlit_init

os.environ.setdefault("OPENLIT_API_KEY", "<your-api-key>")
os.environ.setdefault("OPENLIT_SERVICE_NAME", "agent-orchestrator")
os.environ.setdefault("OPENLIT_ENVIRONMENT", "production")
os.environ.setdefault("OPENLIT_FLEET_HUB_URL", "https://fleet.openlit.io")

openlit_init()
```

```typescript
import { initOpenlit } from '@openlit/sdk';

process.env.OPENLIT_API_KEY = process.env.OPENLIT_API_KEY ?? '<your-api-key>';
process.env.OPENLIT_SERVICE_NAME = 'rag-gateway';
process.env.OPENLIT_ENVIRONMENT = 'production';
process.env.OPENLIT_FLEET_HUB_URL = 'https://fleet.openlit.io';

initOpenlit();
```

Those environment variables mirror the docs exactly. `OPENLIT_FLEET_HUB_URL` binds the service to the Fleet Hub tenancy, while the service name and environment propagate through traces, spans, and metrics automatically. No manual wrappers, decorators, or exporter code is required—OpenLIT provisions trace providers, metric readers, and log emitters under the hood for Python, TypeScript, and Java SDKs.

### 2. Deploy the OpenLIT Operator with Fleet Hub Enabled

Fleet Hub is surfaced by the OpenLIT Operator. If you already run it, upgrade the release with the `fleetHub.enabled` flag. Otherwise, use Helm to install the latest chart (as described in the [`operator/installation`](https://docs.openlit.io/latest/operator/installation) guide).

```bash
helm repo add openlit https://charts.openlit.io
helm repo update

kubectl create namespace openlit
helm upgrade --install openlit-operator openlit/openlit-operator \
  --namespace openlit \
  --set fleetHub.enabled=true \
  --set fleetHub.domain=fleet.openlit.io \
  --set fleetHub.apiKeySecret=platform-fleet-hub
```

The Operator registers each OpenTelemetry Collector custom resource with Fleet Hub. It also provisions a token secret (`platform-fleet-hub`) that authenticates API calls back to the control plane. Because Fleet Hub is multi-tenant by design, you can isolate environments by namespace or cluster while maintaining a single administrative surface.

### 3. Register Collector Fleets and Group Policies

Once the Operator syncs, log in to the Fleet Hub UI. The dashboard lists every collector with live heartbeat status, version, and the pipelines currently applied. Structure your topology facing the AI organization:

- **Inference Fleet (GPU Regions)** – Dedicated collectors close to inference pods; enable tail sampling with 1% of low-latency requests captured fully.
- **RAG Fleet (Vector + Embedding)** – Collectors near the retrieval pods; attach attribute processors to annotate spans with `rag.corpus` and `embedding.provider`.
- **Experimentation Fleet (Playground + AB Tests)** – Looser quotas, aggressive sampling to keep costs down while still capturing error spans.

Fleet Hub lets you define policy bundles (transform, sampling, exporters) and apply them to groups in one operation. If you prefer infrastructure-as-code, fetch the configuration as YAML:

```bash
openlit fleet-hub export --group rag-fleet --format yaml > rag-fleet-policy.yaml
```

Commit the file to your platform repo, and reload it with:

```bash
openlit fleet-hub apply --file rag-fleet-policy.yaml
```

Behind the scenes, Fleet Hub updates the Operator CRDs, and each collector reconciles within seconds without restarts. For AI workloads that spike unpredictably, you can combine this with HPA targets or KEDA scalers; Fleet Hub keeps the settings uniform regardless of the replica count.

### 4. Wire Fleet Hub Insights into Day-2 Operations

Fleet Hub is more than a configuration panel. It surfaces control-plane metrics that make multi-collector management measurable:

| Signal | What It Shows | Why It Matters for AI Platforms |
| --- | --- | --- |
| Collector Health | Heartbeat latency, last config push, binary version | Detect stale collectors before they drop spans from GPU inference jobs. |
| Routing Efficacy | Exporter success rate, throttled exports | Confirm high-volume embedding jobs are not saturating downstream Grafana Tempo or ClickHouse clusters. |
| Policy Compliance | Drift detection, diff history | Audit that all LangChain services still apply personally identifiable information (PII) scrubbing processors. |
| Fleet Cost | Aggregated volume per exporter | Enforce budgets by routing experimentation telemetry to lower-cost sinks. |

Pipeline changes are annotated with the user, Git commit, and related incident ticket so postmortems stay crisp. Because routes are centrally declared, you can dynamically split traffic—e.g. send 20% of high-cardinality spans to a second Tempo cluster while keeping the rest in ClickHouse—without touching service code.

### 5. Validate Automatic Tracing End-to-End

Instrumentation only counts when spans arrive with the right context. Use the Fleet Hub validation workflow to trace a real RAG request:

1. Trigger a request against your orchestrator (for example, `POST /chat/completions`).
2. Fleet Hub’s live trace explorer stitches spans from the Python orchestration layer, the TypeScript gateway, the embedding provider, and the vector lookup automatically via `trace_id`.
3. Confirm attributes such as `llm.provider`, `embedding.model`, `rag.hit_count`, and `llm.latency_ms` appear—these are emitted by OpenLIT out of the box for supported providers including OpenAI, Anthropic, Mistral, Groq, Hugging Face, and Amazon Bedrock.
4. Use the “Collector Path” overlay to verify which collectors touched the trace. In multi-region deployments, you should see the expected sequence: edge collector → regional aggregator → export pipeline.

Fleet Hub also exposes conformance tests for log signals. You can schedule daily runs that send synthetic prompts to ensure logging processors (for redaction or sampling) still conform after a policy update.

### 6. Bring the Fleet Graph to Incident Response

Add the Fleet Hub topology widget to your status dashboards. The diagram below is an example of the control-plane view you can embed in runbooks:

![Fleet Hub topology diagram](/static/images/fleet-hub-topology.webp)

The widget links every collector node to its owner squad, environment, and export targets. During an incident—say a sudden spike in streaming token latency—you can instantly identify whether the GPU region’s collector is alive, whether routing is falling back to a failover exporter, and which policies changed recently. This shortens mean time to detect (MTTD) for AI degradations, where traces and metrics must be correlated across dozens of services.

## Benefits and Outcomes

Fleet Hub delivers measurable operational advantages:

- **Unified change control** – A single audit trail for collector updates replaces ad-hoc Helm values or `otel-collector-config` ConfigMaps. You see who changed what, when, and why.
- **Faster remediation loops** – Live drift detection alerts operators within minutes if a collector diverges from the desired policy, preventing trace drops that would otherwise mask outages.
- **Cost governance** – Volume analytics let you cap exporter spend; you can cap experimentation fleets to lower-cost observability backends without sacrificing production fidelity.
- **Provider-aware insights** – Because OpenLIT automatically captures attributes for OpenAI, Anthropic, Vertex AI, Groq, Cohere, Ollama, Hugging Face, Amazon Bedrock, and more, Fleet Hub dashboards surface per-provider SLOs without extra modeling.
- **Security and compliance** – Central policies guarantee sensitive prompts and embeddings are redacted, hashed, or dropped before leaving controlled collectors.

Real platform teams report up to 40% reduction in “who changed the collector?” escalations, and incident war rooms shrink because topology context is native. Instead of paging infrastructure engineers at 3 a.m., platform SREs can re-route traffic or roll back a policy with a few clicks.

OpenLIT’s differentiator is this combination of one-line instrumentation and fleet-wide governance. Other observability stacks expect you to hand-tune OpenTelemetry pipelines service by service; OpenLIT ships the processors, semantic conventions, and AI-specific attributes centrally. Isn’t it time your LLM platform had one source of truth for telemetry pipelines as well?

## When It’s Required/Recommended

Consider Fleet Hub a must-have when:

- You operate more than three collectors across regions or cloud providers and need a canonical inventory.
- You support mixed workloads—GPU inference, vector retrieval, streaming responses—and require differentiated policies per lane.
- You have at least one regulated environment (finance, healthcare, education) and must prove prompt redaction or token retention rules centrally.
- You orchestrate multi-team or partner-built agents, where enforcement through pull requests alone risks configuration drift.
- You plan to adopt signal-specific backends (Tempo, ClickHouse, BigQuery, New Relic, Datadog, etc.) and need dynamic routing without redeploying services.

Smaller teams can still benefit, but Fleet Hub shines once AI infrastructure becomes federated. It keeps the control plane thin while letting individual squads move fast.

## Conclusion

Fleet Hub redefines how AI platform teams manage observability at scale. By pairing it with automatic OpenLIT instrumentation (`openlit.init()` everywhere), you gain precise control over telemetry routing, cost, and compliance without burdening application engineers. Start by enabling the Operator flag, grouping collectors into meaningful fleets, and wiring the topology widget into incident response. Then iterate: apply redaction policies, experiment with exporter routing, and extend governance to new teams as they onboard.

Ready to see every collector in your AI platform from a single pane of glass, and ship changes confidently even as fleets multiply?
